{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c76e36f",
   "metadata": {},
   "source": [
    "# Data Prep for Earnings Call App\n",
    "\n",
    "This notebook shows how to create the data required to run the earnings call app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371e2297",
   "metadata": {},
   "source": [
    "## Step 0: Fill Out Variables\n",
    "\n",
    "\n",
    "To run this script, create a dictionary for the transcripts you would like to analyze (with their url) as well as the url of the transcript you would like to do the detailed analysis on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773a46fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "helium_url = ''\n",
    "api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a63ab031",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = {\n",
    "    '2024 Q1': {'url': \"https://www.fool.com/earnings/call-transcripts/2023/09/20/fedex-fdx-q1-2024-earnings-call-transcript/\"},\n",
    "    '2023 Q4': {'url': \"https://www.fool.com/earnings/call-transcripts/2023/06/20/fedex-fdx-q4-2023-earnings-call-transcript/\"},\n",
    "    '2023 Q3': {'url': \"https://www.fool.com/earnings/call-transcripts/2023/03/17/fedex-fdx-q3-2023-earnings-call-transcript/\"},\n",
    "    '2023 Q2': {'url': \"https://www.fool.com/earnings/call-transcripts/2022/12/21/fedex-fdx-q2-2023-earnings-call-transcript/\"},\n",
    "    '2023 Q1': {'url': \"https://www.fool.com/earnings/call-transcripts/2022/09/23/fedex-fdx-q1-2023-earnings-call-transcript/\"},\n",
    "    '2022 Q4': {'url': \"https://www.fool.com/earnings/call-transcripts/2022/06/24/fedex-fdx-q4-2022-earnings-call-transcript/\"},\n",
    "    '2022 Q3': {'url': \"https://www.fool.com/earnings/call-transcripts/2022/03/18/fedex-fdx-q3-2022-earnings-call-transcript/\"},\n",
    "    '2022 Q2': {'url': \"https://www.fool.com/earnings/call-transcripts/2021/12/17/fedex-corporation-fdx-q2-2022-earnings-call-transc/\"},\n",
    "    '2022 Q1': {'url': \"https://www.fool.com/earnings/call-transcripts/2021/09/21/fedex-corporation-fdx-q1-2022-earnings-call-transc/\"},\n",
    "    '2021 Q4': {'url': \"https://www.fool.com/earnings/call-transcripts/2021/06/25/fedex-corp-fdx-q4-2021-earnings-call-transcript/\"},\n",
    "    '2021 Q3': {'url': \"https://www.fool.com/earnings/call-transcripts/2021/03/18/fedex-corp-fdx-q3-2021-earnings-call-transcript/\"},\n",
    "    '2021 Q2': {'url': \"https://www.fool.com/earnings/call-transcripts/2020/12/17/fedex-corp-fdx-q2-2021-earnings-call-transcript/\"},\n",
    "    '2021 Q1': {'url': \"https://www.fool.com/earnings/call-transcripts/2020/09/15/fedex-corp-fdx-q1-2021-earnings-call-transcript/\"},\n",
    "    '2020 Q4': {'url': \"https://www.fool.com/earnings/call-transcripts/2020/06/30/fedex-corp-fdx-q4-2020-earnings-call-transcript.aspx\"},\n",
    "    '2020 Q3': {'url': \"https://www.fool.com/earnings/call-transcripts/2020/03/17/fedex-corp-fdx-q3-2020-earnings-call-transcript.aspx\"},\n",
    "    '2020 Q2': {'url': \"https://www.fool.com/earnings/call-transcripts/2019/12/17/fedex-corp-fdx-q2-2020-earnings-call-transcript.aspx\"},\n",
    "    '2020 Q1': {'url': \"https://www.fool.com/earnings/call-transcripts/2019/09/18/fedex-corp-fdx-q1-2020-earnings-call-transcript.aspx\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6294b720",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_transcript_url = transcripts.get(\"2024 Q1\").get('url')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880d6210",
   "metadata": {},
   "source": [
    "## Step 1: Create all_transcripts.json\n",
    "\n",
    "The `all_transcripts.json` file contains information on a list of transcripts across multiple quarters. For each transcript, Enterprise h2oGPT calculates the sentiment rating, the reason for that rating, and a summary of what each speaker said.\n",
    "\n",
    "To begin fill in the helium url and api_key as well as the list of transcripts you would like the code to rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f508031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o_helium import Helium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c7ff3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "helium = Helium(address=helium_url, \n",
    "                api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5faa77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in transcripts.items():\n",
    "    # Create collection\n",
    "    collection_id = helium.create_collection(name=k, \n",
    "                                             description=\"{} Fedex Earnings Call Transcript\".format(k))\n",
    "    transcripts[k]['collection_id'] = collection_id\n",
    "        \n",
    "    # Ingest url\n",
    "    helium.ingest_website(collection_id, v.get('url'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6b01ce3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_prompt = '''\n",
    "Rate the sentiment of the transcript from 1 to 5. \n",
    "Write the rating in a table with columns: 'Rating' and 'Reason for Rating'. \n",
    "Only respond with the table, no additional text.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0706931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_speakers = '''\n",
    "Summarize what each speaker said in the transcript. \n",
    "Write the answer in a table with columns: 'Speaker' and 'Summary'. \n",
    "Only respond with the table, no additional text.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "607a340e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatting with 2024 Q1 transcript\n",
      "Chatting with 2023 Q4 transcript\n",
      "Chatting with 2023 Q3 transcript\n",
      "Chatting with 2023 Q2 transcript\n",
      "Chatting with 2023 Q1 transcript\n",
      "Chatting with 2022 Q4 transcript\n",
      "Chatting with 2022 Q3 transcript\n",
      "Chatting with 2022 Q2 transcript\n",
      "Chatting with 2022 Q1 transcript\n",
      "Chatting with 2021 Q4 transcript\n",
      "Chatting with 2021 Q3 transcript\n",
      "Chatting with 2021 Q2 transcript\n",
      "Chatting with 2021 Q1 transcript\n",
      "Chatting with 2020 Q4 transcript\n",
      "Chatting with 2020 Q3 transcript\n",
      "Chatting with 2020 Q2 transcript\n",
      "Chatting with 2020 Q1 transcript\n"
     ]
    }
   ],
   "source": [
    "for k, v in transcripts.items():\n",
    "    \n",
    "    print(\"Chatting with {} transcript\".format(k))\n",
    "    \n",
    "    chat_session_id = helium.create_chat_session(v.get('collection_id'))\n",
    "    with helium.connect(chat_session_id) as session:\n",
    "        \n",
    "        reply = session.query(ratings_prompt, timeout=10600)\n",
    "        transcripts[k]['ratings_table'] = reply.content\n",
    "        \n",
    "        reply = session.query(summarize_speakers, timeout=10600)\n",
    "        transcripts[k]['speakers_table'] = reply.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "c1621fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./static/all_transcripts.json\", \"w\") as outfile: \n",
    "    json.dump(transcripts, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400df16c",
   "metadata": {},
   "source": [
    "## Step 2: Create chunked_transcript.json\n",
    "\n",
    "For a single transcript, the code will chunk the transcript by speaker and calculate the overall sentiment and defensiveness per segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "1d8223be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from h2ogpt_client import Client as h2o_Client  \n",
    "    \n",
    "    \n",
    "def chunk_speakers(url):\n",
    "    \n",
    "    chunks = {}\n",
    "    \n",
    "    url_link = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    file = bs.BeautifulSoup(url_link.text, \"lxml\")\n",
    "    \n",
    "    idx = []\n",
    "    paragraphs = file.select('p')\n",
    "    for i in range(len(paragraphs)):\n",
    "        h2 = paragraphs[i].find_previous('h2')\n",
    "        if h2 is not None:\n",
    "            if h2.text == \"Prepared Remarks:\":\n",
    "                idx = idx + [i]  \n",
    "    start_idx = min(idx)\n",
    "    \n",
    "    idx = []\n",
    "    for i in range(len(paragraphs)):\n",
    "        if ('</strong> -- <em>' in paragraphs[i].decode()) | (paragraphs[i].decode() == '<p><strong>Operator</strong></p>'):\n",
    "            idx = idx + [i]\n",
    "    idx = pd.DataFrame({'start_idx': idx})\n",
    "    idx['end_idx'] = idx.start_idx.shift(-1)\n",
    "    idx = idx.dropna()\n",
    "    idx['end_idx'] = (idx.end_idx).astype(int)     \n",
    "    idx = idx[idx.start_idx >= start_idx]\n",
    "    \n",
    "    for i, row in idx.iterrows():\n",
    "        speaker = paragraphs[row.start_idx].text\n",
    "        dialogue = \" \".join([p.text for p in paragraphs[(row.start_idx+1):row.end_idx]])\n",
    "        chunks[i] = {'speaker': speaker, \n",
    "                    'text': '{}: {}'.format(speaker, dialogue),\n",
    "                     'xml_text': \" \".join([str(p.decode()) for p in paragraphs[(row.start_idx+1):row.end_idx]])\n",
    "                   }\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ae3a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_client = h2o_Client(\"https://gpt-internal.h2o.ai/\")\n",
    "\n",
    "chunks = chunk_speakers(detailed_transcript_url)\n",
    "\n",
    "for k, v in chunks.items():\n",
    "    if k > 0:\n",
    "        print(k)\n",
    "        chunk = v.get('text')\n",
    "        previous_chunk = chunks.get(k-1).get('text')\n",
    "        chunk_prompt = \"\"\"\n",
    "        Here is a piece of a transcript: {} \n",
    "        Rate the response based on defensiveness from 1 to 3. 1 being not defensive at all, 2 being somewhat defensive, 3 being very defensive.\n",
    "        Write the answer as a Python dictionary with the keys: \"Rating\" and \"Reason for Rating\". Only respond with the dictionary.\n",
    "        Here is the response: {}\n",
    "        \"\"\".format(previous_chunk, chunk)\n",
    "        text_completion = llama_client.text_completion.create(max_output_length=1024, \n",
    "                                                              temperature=0.1, \n",
    "                                                              repetition_penalty=1.2)\n",
    "        c_summary = text_completion.complete_sync(chunk_prompt)\n",
    "        chunks[k]['defensiveness'] = c_summary\n",
    "        \n",
    "        chunk_prompt = \"\"\"\n",
    "        Here is a piece of a transcript: {} \n",
    "        Rate the response based on sentiment from 1 to 5. 1 being highly negative, 3 being neutral, 5 being highly positive.\n",
    "        Write the answer as a Python dictionary with the keys: \"Rating\" and \"Reason for Rating\". Only respond with the dictionary.\n",
    "        Here is the response: {}\n",
    "        \"\"\".format(previous_chunk, chunk)\n",
    "        text_completion = llama_client.text_completion.create(max_output_length=1024, \n",
    "                                                              temperature=0.1, \n",
    "                                                              repetition_penalty=1.2)\n",
    "        c_summary = text_completion.complete_sync(chunk_prompt)\n",
    "\n",
    "        chunks[k]['sentiment'] = c_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea4e6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./static/chunked_transcript.json\", \"w\") as outfile: \n",
    "    json.dump(chunks, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4218d58",
   "metadata": {},
   "source": [
    "## Step 3: Daily Stock Price Table\n",
    "\n",
    "Create a csv file named daily_stock_price.csv with columns: `Date` and `Close` for the company who's earnings transcripts you've supplied.  The stock price data should coincide withe quarters of transcripts you are analyzing.  For example, if I am analyzing earnings transcripts from 2022 Q1 and 2022 Q2, then I should have stock prices for the first half of 2022.\n",
    "\n",
    "For my demo, I took the [S&P 500 Data](https://www.kaggle.com/datasets/camnugent/sandp500) and filtered it down to the FEDEX ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72189b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price = pd.read_csv(\"./static/daily_stock_price.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1058e926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>228.449997</td>\n",
       "      <td>234.149994</td>\n",
       "      <td>217.820007</td>\n",
       "      <td>217.979996</td>\n",
       "      <td>215.693161</td>\n",
       "      <td>32632000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>217.509995</td>\n",
       "      <td>250.080002</td>\n",
       "      <td>213.809998</td>\n",
       "      <td>247.899994</td>\n",
       "      <td>245.299271</td>\n",
       "      <td>56511200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>247.110001</td>\n",
       "      <td>270.950012</td>\n",
       "      <td>246.179993</td>\n",
       "      <td>269.950012</td>\n",
       "      <td>268.622192</td>\n",
       "      <td>38529200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>269.279999</td>\n",
       "      <td>270.579987</td>\n",
       "      <td>254.500000</td>\n",
       "      <td>261.019989</td>\n",
       "      <td>259.736084</td>\n",
       "      <td>36049400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>262.750000</td>\n",
       "      <td>268.380005</td>\n",
       "      <td>246.050003</td>\n",
       "      <td>261.850006</td>\n",
       "      <td>260.562012</td>\n",
       "      <td>28807100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date        Open        High         Low       Close   Adj Close  \\\n",
       "55  2023-05-01  228.449997  234.149994  217.820007  217.979996  215.693161   \n",
       "56  2023-06-01  217.509995  250.080002  213.809998  247.899994  245.299271   \n",
       "57  2023-07-01  247.110001  270.950012  246.179993  269.950012  268.622192   \n",
       "58  2023-08-01  269.279999  270.579987  254.500000  261.019989  259.736084   \n",
       "59  2023-09-01  262.750000  268.380005  246.050003  261.850006  260.562012   \n",
       "\n",
       "      Volume  \n",
       "55  32632000  \n",
       "56  56511200  \n",
       "57  38529200  \n",
       "58  36049400  \n",
       "59  28807100  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_price.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7858e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
